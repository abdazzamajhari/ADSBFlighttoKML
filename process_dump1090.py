# process_dump1090, processes the CSV files generated by capture_dump1090.py
# and generate KML files of flights captured
#
# Copyright 2017 by Michael Tan <michael.tan@gmail.com>
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice,
#    this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright notice,
#    this list of conditions and the following disclaimer in the documentation
#    and/or other materials provided with the distribution.
#
# 3. Neither the name of the copyright holder nor the names of its contributors
#    may be used to endorse or promote products derived from this software
#    without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
# THE POSSIBILITY OF SUCH DAMAGE.

import os, sys

os.environ['SPARK_HOME'] = "C:\\spark\\spark-2.0.2-bin-hadoop2.6"
sys.path.append(os.environ['SPARK_HOME']+"\\python\\")
sys.path.append(os.environ['SPARK_HOME']+"\\python\\lib\\")
sys.path.append(os.environ['SPARK_HOME']+"\\python\\lib\\py4j-0.10.3-src.zip")

import csv
import shutil
import pyspark.sql.functions as psf
import tkFileDialog
import subprocess

from pyspark import SparkContext, SparkConf, SparkFiles
from pyspark.sql import SparkSession
from pyspark.sql.types import *
from pyspark.sql.window import Window
from Tkinter import Tk

spark = SparkSession.builder.appName("default").getOrCreate()

allFlights = True     # show all flights or just the ones departing/arriving based on coordinates/altitude further down
showHolding = True    # show the flights that are in the holding pattern, may catch some that aren't truly in a holding pattern
mlat = False          # false to show only flights with proper coordination or true to show everything including coordiantes obtained via multilateration
ADSBDir = "d:/adsb/"  # where all of the CSV files are

Tk().withdraw()
CSVfilepath = tkFileDialog.askopenfilename(initialdir = ADSBDir,title = "Select adsbexchange CSV file",filetypes = (("CSV files","*.csv"),("all files","*.*")))

def has_column(df, col):
    try:
        df[col]
        return True
    except AnalysisException:
        return False

if CSVfilepath == '':
    print ('No file provided')
else:

    # the coordinates and altitude are used to identify planes that falls within these parameters, in identifying
    # planes that are arriving/departing from an airport if an airport is near you
    #
    # if you do not wish to filter planes, set allFlights = True above.
    #
    # use https://developers.google.com/maps/documentation/javascript/examples/rectangle-event to help define the
    # coordinates

    minLat = '43.622019'        # minimum latitude
    maxLat = '43.732630'        # maximum latitude
    minLon = '-79.731840'       # minimum longitude
    maxLon = '-76.525840'       # maximum longitude
    altitude = '5000'           # altitude in feet
    mlat = False                # all ADS-B data is in scope, include coordinates obtained by multilateration (MLAT)

    CSVfilename = os.path.basename(CSVfilepath)
    CSVfilename = str(os.path.splitext(CSVfilename)[0]).replace('dump1090_','')
    CSVfolder = str(os.path.dirname(CSVfilepath))

    adsbDf = spark.read.csv(CSVfilepath, header=True, inferSchema=True, sep=',',  dateFormat="yyyy-MM-dd HH:mm:ss")

    if not(has_column(adsbDf,"mlat")):
        adsbDf = adsbDf.withColumn("mlat", psf.lit(None))

    adsbDf = adsbDf.filter("altitude<>'ground'")

    adsbDf.createOrReplaceTempView("adsb")

    # note there are flights that sometimes use 00000000 as a flight number, replace that with the ICAO
    # flights that are empty, use ICAO

    if allFlights is True:
        # retrieve all flights
        if mlat is False:
            # retrieve coordinates obtained via ADS-B, exclude MLAT
            adsbTable = spark.sql('select UTC, if(isnull(flight), icao, if(flight="00000000", icao, flight)) as \
                flight, lon, lat, altitude from adsb where mlat = false order by UTC, flight')
        else:
            # retrieve coordinates obtained via ADS-B and MLAT
            adsbTable = spark.sql('select UTC, if(isnull(flight), icao, if(flight="00000000", icao, flight)) as \
                flight, lon, lat, altitude from adsb order by UTC, flight')
    else:
        # retrieve only flights that falls within the coordinate and altitude
        if mlat == False:
            # retrieve coordinates obtained via ADS-B, exclude MLAT
            adsbTable = spark.sql('select UTC, flight, lon, lat, altitude from (select UTC, if(isnull(flight), icao, \
                if(flight="00000000",icao,flight)) as flight, lon, lat, altitude from adsb order by UTC, flight) as B \
                where B.flight in (select flight from (select if(isnull(flight), icao, if(flight="00000000",icao, \
                flight)) as flight, lon, lat, altitude from adsb where mlat = false) as A where (lat > ' + minLat + \
                ' and lat < ' + maxLat + ' and lon > ' + minLon + ' and lon < ' + maxLon + '  and altitude < ' + \
                altitude + ') group by flight) order by UTC')
        else:
            # retrieve coordinates obtained via ADS-B and MLAT
            adsbTable = spark.sql('select UTC, flight, lon, lat, altitude from (select UTC, if(isnull(flight), icao, \
                if(flight="00000000",icao,flight)) as flight, lon, lat, altitude from adsb order by UTC, flight) as B \
                where B.flight in (select flight from (select if(isnull(flight), icao, if(flight="00000000",icao, \
                flight)) as flight, lon, lat, altitude from adsb) as A where (lat > ' + minLat + ' and lat < ' + \
                maxLat + ' and lon > ' + minLon + ' and lon < ' + maxLon + '  and altitude < ' + altitude + ') group \
                by flight) order by UTC')

    adsbTable = adsbTable.dropDuplicates(['flight','lon','lat'])

    # the next set of lines will handle the scenario where the same flight number from one airport arrives at another
    # airport, then departs to another airport we do not want to treat this as one flight, rather multiple flights, for
    # example, if we have flight ACA108 that comes in from Montreal to Toronto then leaves for Winnipeg, we will have
    # ACA108-0 and ACA108-1
    #
    # if there was just one flight number, then only -0 is appended

    # partition the flight by UTC
    window_flightNum_UTC =  Window.partitionBy("flight").orderBy("UTC")

    # calculate the deltaTime between the previous and current coordinate for each flight
    adsbDf=adsbTable.withColumn("deltaTime", psf.unix_timestamp('UTC') - psf.lag(psf.unix_timestamp('UTC')). \
        over(window_flightNum_UTC))

    # create a trigger when the time elapse from the previous coordinates to the next is more than 1200 seconds
    # (20 minutes) note that this isn't foolproof, if there is gaps in your coverage that is 20 minutes or longer then
    # this will break that one flight into two separate flights, adjust the 1200 seconds below to suit your
    # requirements
    adsbDf1=adsbDf.withColumn("trigger", psf.when(adsbDf.deltaTime>1200,1).otherwise(0))

    # create the suffix for the flight by using the cumulative sum of the triggers for each flight
    adsbDf2=adsbDf1.withColumn("suffix", psf.sum(adsbDf1.trigger).over(window_flightNum_UTC))

    # now bring the flight and suffix together to create the final flight, such as ACA108-0, ACA108-1, etc., these
    # will be the unique flights
    adsbDf3=adsbDf2.withColumn("flightFinal",psf.concat(adsbDf2.flight, psf.lit("-"), adsbDf2.suffix))

    adsbDf4=adsbDf3.repartition('flightFinal')
    window_flightNum_UTC =  Window.partitionBy("flightFinal").orderBy("UTC")

    if showHolding == True:
        # option to show only planes in a holding pattern, note that the below is NOT foolproof depending on flight
        # route
        #
        # first we calculate the bearing change from the previous coordinate to the current coordinate, on how to
        # calculate bearing see:
        #
        # https://www.mrexcel.com/forum/excel-questions/626081-calculate-bearing-direction-between-2-coordinates.html

        adsbDf5 = adsbDf4.withColumn("lon_rad",adsbDf4.lon*3.14159265358979/180)
        adsbDf6 = adsbDf5.withColumn("lat_rad",adsbDf4.lat*3.14159265358979/180)
        adsbDf7 = adsbDf6.withColumn("bearing", psf.when(psf.isnull(psf.lag('lat_rad').over(window_flightNum_UTC)),0). \
            otherwise(psf.atan2(psf.sin(adsbDf6.lon_rad-psf.lag('lon_rad').over(window_flightNum_UTC))* \
            psf.cos('lat_rad'),psf.cos(psf.lag('lat_rad').over(window_flightNum_UTC))*psf.sin('lat_rad')- \
            psf.sin(psf.lag('lat_rad').over(window_flightNum_UTC))*psf.cos('lat_rad')*psf.cos(adsbDf6.lon_rad- \
            psf.lag('lon_rad').over(window_flightNum_UTC)))/( 3.14159265358979/180)))
        adsbDf8 = adsbDf7.withColumn("bearing_final",psf.when(adsbDf7.bearing < 0, adsbDf7.bearing+360). \
            otherwise(adsbDf7.bearing))

        # calculate bearing change from the previous coordinate to the current
        adsbDf9 = adsbDf8.withColumn("bearing_change", psf.when(psf.lag('bearing_final'). \
            over(window_flightNum_UTC)==0,0).otherwise(psf.when(adsbDf8.bearing_final==0,0). \
            otherwise(psf.lag('bearing_final').over(window_flightNum_UTC)-adsbDf8.bearing_final)))

        # crude way of ignoring changes when the bearing crosses zero degrees, such as 350 to 10 degrees, because it's
        # not really 340 degree change but rather 20 degrees, but I'm too lazy to calculate this so ignore anything
        # thathas a bearing change of 200 degrees
        adsbDf10 = adsbDf9.withColumn("bearing_change_final", psf.when(psf.abs(adsbDf9.bearing_change)>200,0). \
            otherwise(adsbDf9.bearing_change))

        # run cumulative sum of bearing change for each unique flight, basically if a plane is in a holding pattern,
        # most likely it will do at least one full loop
        adsbDf11 = adsbDf10.withColumn("bearing_total_change", psf.sum(adsbDf10.bearing_change_final). \
            over(window_flightNum_UTC))

        # identify the the planes that were in a holding pattern but looking for total bearing change greater than 360
        # degrees... this is NOT foolproof, it may catch regular flights due to it's flight path
        holdingDf = adsbDf11.filter(psf.abs(adsbDf11.bearing_total_change)>360)
        flightHolding = holdingDf.select('flightFinal').distinct()
        flightHolding = flightHolding.withColumnRenamed("flightFinal","flight")
        flights = flightHolding.join(adsbDf4, (flightHolding.flight==adsbDf4.flightFinal))
    else:
        #capture all flights
        flights = adsbDf4

    # generate the results, which are CSV files
    flights.sortWithinPartitions("UTC",ascending=True).select('UTC','flightFinal','lon','lat','altitude').write. \
        partitionBy('flightFinal').mode('overwrite').csv(os.path.join(CSVfolder+'/',CSVfilename), header=False, sep=',')

    # create the KML files for each CSV file
    count = 0
    for d in os.listdir(CSVfolder+"/"+CSVfilename):
        if os.path.isdir(CSVfolder+"/"+CSVfilename+"/"+d):
            for f in os.listdir(CSVfolder+"/"+CSVfilename+"/"+d):
                if os.path.isfile(CSVfolder+"/"+CSVfilename+"/"+d+"/"+f):
                    if f.lower().endswith('csv'):
                        count=count+1
                        fKML = open(CSVfolder+'/'+CSVfilename+'/'+d+'/'+d.replace('flightFinal=','')+'.kml', 'w')
                        fKML.write('<?xml version="1.0" encoding="UTF-8"?>\n')
                        fKML.write('<kml xmlns="http://www.opengis.net/kml/2.2">\n')
                        fKML.write('<Placemark>\n')
                        fKML.write('  <name>'+d.replace('flightFinal=','')+'</name>\n')
                        # adjust the line style to suit your needs, to do this, after importing a KML file into Google
                        # Earth, adjust the style then export the KML file and take the styles there and replace the
                        # below

                        fKML.write('  <Style id="failed">\n')
                        fKML.write('    <LineStyle>\n')
                        fKML.write('      <color>7f00ffff</color>\n')
                        fKML.write('    </LineStyle>\n')
                        fKML.write('    <PolyStyle>\n')
                        fKML.write('      <color>7f0000ff</color>\n')
                        fKML.write('      <outline>0</outline>\n')
                        fKML.write('    </PolyStyle>\n')
                        fKML.write('  </Style>\n')
                        fKML.write('  <Style id="sh_ylw-pushpin0000">\n')
                        fKML.write('    <IconStyle>\n')
                        fKML.write('      <scale>1.2</scale>\n')
                        fKML.write('    </IconStyle>\n')
                        fKML.write('    <LineStyle>\n')
                        fKML.write('      <color>7f00ffff</color>\n')
                        fKML.write('    </LineStyle>\n')
                        fKML.write('    <PolyStyle>\n')
                        fKML.write('      <color>7f0000ff</color>\n')
                        fKML.write('      <outline>0</outline>\n')
                        fKML.write('    </PolyStyle>\n')
                        fKML.write('  </Style>\n')
                        fKML.write('  <StyleMap id="mfailed00">\n')
                        fKML.write('    <Pair>\n')
                        fKML.write('      <key>normal</key>\n')
                        fKML.write('      <styleUrl>#failed</styleUrl>\n')
                        fKML.write('    </Pair>\n')
                        fKML.write('    <Pair>\n')
                        fKML.write('      <key>highlight</key>\n')
                        fKML.write('      <styleUrl>#sh_ylw-pushpin0000</styleUrl>\n')
                        fKML.write('    </Pair>\n')
                        fKML.write('  </StyleMap>\n')

                        # end of line style

                        fKML.write('  <LineString>\n')
                        fKML.write('    <extrude>1</extrude>\n')
                        fKML.write('    <altitudeMode>relativeToSeaFloor</altitudeMode>\n')
                        fKML.write('    <coordinates>\n')
                        inputCSV = csv.reader(open(CSVfolder+"/"+CSVfilename+"/"+d+"/"+f,'r'))
                        bPastFirst = False

                        for row in inputCSV:
                            if row[3] <> "":
                                if bPastFirst is True:
                                    try:
                                        float(row[3])     # test to see if we have a numeric value, if not, ignore it
                                    except:
                                        row[3] = prevAltitude
                                    if abs(float(prevAltitude)-float(row[3])) < 20000:
                                        # sometimes there is error in the altitude, so if the altitude change is more
                                        # than 20,000 feet, then we'll use the altitude from the previous coordinate
                                        # it's a bit of a bruteforce method

                                        fKML.write(row[1]+','+row[2]+','+str(float(row[3])*0.3048)+'\n')
                                        prevAltitude = row[3]
                                    else:
                                        fKML.write(row[1]+','+row[2]+','+str(float(prevAltitude)*0.3048)+'\n')
                                else:
                                    prevAltitude = row[3]
                                    fKML.write(row[1]+','+row[2]+','+str(float(row[3])*0.3048)+'\n')
                                    bPastFirst = True

                        del inputCSV
                        fKML.write('    </coordinates>\n')
                        fKML.write('  </LineString>\n')
                        fKML.write('</Placemark>\n')
                        fKML.write('</kml>\n')
                        fKML.close()
                        os.rename(CSVfolder+'/'+CSVfilename+'/'+d+'/'+d.replace('flightFinal=','')+'.kml', CSVfolder+ \
                            '/'+CSVfilename+'/'+d.replace('flightFinal=','')+'.kml')
                        shutil.rmtree(CSVfolder+'/'+CSVfilename+'/'+d, ignore_errors=True)

    # make things easy for me, browse the folder that contains the KML files
    subprocess.call('explorer ""'+CSVfolder.replace('/','\\')+"\\"+CSVfilename+'"', shell=True)
